{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e068d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time, os\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_KEYWORDS= 500\n",
    "N_AUTHORS = 2302\n",
    "\n",
    "# The following pytorch code is modified based on workshop 7's jupyter notebook by group 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a819ff0-f599-485a-9a7f-fbc201c06395",
   "metadata": {},
   "source": [
    "### Read train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f368f965-427d-455f-85a3-8c0ae23bf6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = json.load(open('../data/train.json'))\n",
    "train_df = pd.DataFrame(train_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00729311-dcd5-430b-99be-6cbe3a43e1d0",
   "metadata": {},
   "source": [
    "### Pre-process train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "763123cb-c13a-458a-8c02-ddb2e020d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(df, is_test_data= False):\n",
    "    if is_test_data:\n",
    "        pass\n",
    "    else:\n",
    "        df1 = pd.DataFrame(df.author)\n",
    "        df1.columns=['coauthor']\n",
    "        df2 = df.explode('author')\n",
    "        df3 = df1.join(df2)\n",
    "        df3['author_set'] = df3['author'].apply(lambda x: {x})\n",
    "        df3['coauthor_set'] = df3['coauthor'].apply(lambda x: set(x))\n",
    "        df3['coauthor'] = df3['coauthor_set'] - df3['author_set']\n",
    "        df3['coauthor'] = df3['coauthor'].apply(lambda x: list(x))\n",
    "        df3 = df3[['keywords', 'coauthor', 'author']]\n",
    "        mlb_keywords = MultiLabelBinarizer(sparse_output=True, classes=list(range(500)))\n",
    "        keywords_oh = mlb_keywords.fit_transform(df3.keywords).toarray()\n",
    "\n",
    "        mlb_coauthor = MultiLabelBinarizer(sparse_output=True, classes=list(range(2302)))\n",
    "        coauthor_oh = mlb_coauthor.fit_transform(df3.coauthor).toarray()\n",
    "\n",
    "        features = np.hstack((keywords_oh, coauthor_oh))\n",
    "        labels = df3.author.to_list()\n",
    "    \n",
    "    return features, labels, mlb_keywords, mlb_coauthor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb6c377-8889-42ae-9951-c523cb7b41eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, mlb_keywords, mlb_coauthor = preprocess_dataset(train_df)\n",
    "feature_processed = torch.from_numpy(np.array(features)).float()\n",
    "labels_processed = torch.from_numpy(np.array(labels)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf0cf80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32160 32160\n",
      "15840 15840\n"
     ]
    }
   ],
   "source": [
    "# split raw train data into train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(feature_processed, labels_processed, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "print(len(X_train), len(y_train))\n",
    "print(len(X_val), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d789a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set = [], []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    train_set.append((X_train[i], y_train[i]))\n",
    "    \n",
    "for i in range(len(X_val)):\n",
    "    valid_set.append((X_val[i], y_val[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "753aee0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2802])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(valid_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83a72625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MulticlassLogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super(MulticlassLogisticRegression, self).__init__()\n",
    "        \n",
    "        # Define weight and bias\n",
    "        self.W = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty([n_features, n_classes]))) # Weights \n",
    "        self.b = torch.nn.Parameter(torch.zeros([n_classes])) # Biases\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for logistic regression.\n",
    "        Input: Tensor x of shape []\n",
    "        Output: Logits W @ x + b\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        x = x.view(batch_size, -1) # Flatten data, retaining batch size\n",
    "        out = torch.matmul(x, self.W) + self.b # compute scores \n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e8137b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2802, 2302])\n",
      "torch.Size([2302])\n"
     ]
    }
   ],
   "source": [
    "n_features, n_classes = N_KEYWORDS + N_AUTHORS, N_AUTHORS\n",
    "logistic_regression_model = MulticlassLogisticRegression(n_features, n_classes)\n",
    "\n",
    "for p in logistic_regression_model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0665907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, test_loader):\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x, labels = data\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(x)    # Compute scores\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            test_loss += criterion(input=logits, target=labels).item()\n",
    "            test_preds.append(predictions)\n",
    "            test_labels.append(labels)\n",
    "            \n",
    "    test_preds = torch.cat(test_preds)\n",
    "    test_labels = torch.cat(test_labels)\n",
    "    \n",
    "    test_accuracy = torch.eq(test_preds, test_labels).float().mean().item()\n",
    "    \n",
    "    print(f'[TEST]  Mean loss {round(test_loss/len(test_loader), 4)} | Accuracy {round(test_accuracy, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, n_epochs=25):\n",
    "    \"\"\"\n",
    "    Generic training loop for supervised multiclass learning\n",
    "    \"\"\"\n",
    "    LOG_INTERVAL = 256\n",
    "    running_loss, running_accuracy = list(), list()\n",
    "    start_time = time.time()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Iterate by number of epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, labels = data\n",
    "            logits = model(x)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            train_acc = torch.mean(torch.eq(predictions, labels).float()).item()\n",
    "            loss = criterion(input=logits, target=labels)\n",
    "            \n",
    "            loss.backward()          # Backward pass (compute parameter gradients)\n",
    "            optimizer.step()         # Update weight parameter using SGD\n",
    "            optimizer.zero_grad()    # Reset gradients to zero for next iteration\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_accuracy.append(train_acc)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if i % LOG_INTERVAL == 0:  # Log training stats\n",
    "                deltaT = time.time() - start_time\n",
    "                mean_loss = epoch_loss / (i+1)\n",
    "                print(f'[TRAIN] Epoch {epoch} [{i}/{len(train_loader)}]| Mean loss {round(mean_loss, 4)} | Accuracy {round(train_acc, 4)} | Time {round(deltaT, 4)} s'.format(epoch, \n",
    "                    i, len(train_loader), mean_loss, train_acc, deltaT))\n",
    "        \n",
    "        print(f'>>>>>>  Epoch {epoch} Done| Mean loss {round(epoch_loss/len(train_loader), 4)}')\n",
    "\n",
    "        test(model, criterion, test_loader)\n",
    "\n",
    "    return running_loss, running_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afa37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(logistic_regression_model.parameters(), lr=0.2, momentum=0.9)\n",
    "\n",
    "lr_loss, lr_acc = train(logistic_regression_model, train_loader, test_loader, optimizer, n_epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70d60f-f695-4b63-a386-55377ebce0fb",
   "metadata": {},
   "source": [
    "### Transform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e0d4c82-935f-4742-8f9f-20d5dc22c84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue</th>\n",
       "      <th>keywords</th>\n",
       "      <th>year</th>\n",
       "      <th>coauthor</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>[260, 6, 390, 136, 7, 11, 17, 285, 288, 162, 4...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[]</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>[260, 454, 137, 14, 400, 274, 339, 213, 280, 2...</td>\n",
       "      <td>2019</td>\n",
       "      <td>[1001]</td>\n",
       "      <td>2123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>[390, 198, 7, 461, 462, 14, 404, 277, 24, 473,...</td>\n",
       "      <td>2014</td>\n",
       "      <td>[]</td>\n",
       "      <td>1578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[195, 6, 390, 10, 459, 464, 338, 146, 276, 466...</td>\n",
       "      <td>2010</td>\n",
       "      <td>[1347]</td>\n",
       "      <td>2072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162</td>\n",
       "      <td>[64, 1, 260, 457, 73, 147, 282, 27, 156, 43, 3...</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1107]</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  venue                                           keywords  year coauthor  \\\n",
       "0        [260, 6, 390, 136, 7, 11, 17, 285, 288, 162, 4...  2017       []   \n",
       "1    94  [260, 454, 137, 14, 400, 274, 339, 213, 280, 2...  2019   [1001]   \n",
       "2    31  [390, 198, 7, 461, 462, 14, 404, 277, 24, 473,...  2014       []   \n",
       "3     6  [195, 6, 390, 10, 459, 464, 338, 146, 276, 466...  2010   [1347]   \n",
       "4   162  [64, 1, 260, 457, 73, 147, 282, 27, 156, 43, 3...  2016   [1107]   \n",
       "\n",
       "   target  \n",
       "0     988  \n",
       "1    2123  \n",
       "2    1578  \n",
       "3    2072  \n",
       "4     995  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = json.load(open('../data/test.json'))\n",
    "test_df = pd.DataFrame(test_df).T\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2be2523-1750-4363-84a9-0d1cb282dcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2802)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_oh_test = mlb_keywords.transform(test_df.keywords).toarray()\n",
    "coauthor_oh_test = mlb_coauthor.transform(test_df.coauthor).toarray()\n",
    "features_test = np.hstack((keywords_oh_test, coauthor_oh_test))\n",
    "\n",
    "features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1570a-efe3-4b87-8c44-d031e1f42c7d",
   "metadata": {},
   "source": [
    "### Predict Kaggle test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "283a0b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1056,  0.8017, -0.3196,  ..., -1.3770,  0.0972,  3.1753],\n",
      "        [ 1.8976,  0.1104, -0.4413,  ..., -0.2809,  1.4967,  0.4374],\n",
      "        [-2.3686, -1.3717, -0.4697,  ..., -1.3212, -1.4522, -0.4854],\n",
      "        ...,\n",
      "        [ 0.7753, -3.1361,  2.4074,  ...,  0.1092,  0.1472, -1.6790],\n",
      "        [ 1.6290, -0.9589,  1.6027,  ..., -0.7128,  2.3460,  1.6931],\n",
      "        [-0.9993, -0.0970,  0.6584,  ...,  0.3550, -0.1605, -1.2075]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tensor_test = torch.tensor(np.array(features_test)).float()\n",
    "\n",
    "predictions = torch.matmul(tensor_test, logistic_regression_model.W) + logistic_regression_model.b\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6594b0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 2302])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1056,  0.8017, -0.3196,  ..., -1.3770,  0.0972,  3.1753],\n",
       "        [ 1.8976,  0.1104, -0.4413,  ..., -0.2809,  1.4967,  0.4374],\n",
       "        [-2.3686, -1.3717, -0.4697,  ..., -1.3212, -1.4522, -0.4854],\n",
       "        ...,\n",
       "        [ 0.7753, -3.1361,  2.4074,  ...,  0.1092,  0.1472, -1.6790],\n",
       "        [ 1.6290, -0.9589,  1.6027,  ..., -0.7128,  2.3460,  1.6931],\n",
       "        [-0.9993, -0.0970,  0.6584,  ...,  0.3550, -0.1605, -1.2075]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_arr = predictions.tolist()\n",
    "\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a8d54ab-f74b-40ed-bac2-c402420004f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_score_list = []\n",
    "\n",
    "for index, target in test_df.target.iteritems():\n",
    "    prob = predictions_arr[index][target]\n",
    "    prob_score = 1 / (1 + np.exp(-prob))  # sigmoid function\n",
    "    prob_score_list.append(prob_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085b8b6-8990-4e4b-96fb-8d180e4a85e2",
   "metadata": {},
   "source": [
    "### Output result to CSV for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a684352f-2ae8-4e93-a278-eaed06177642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('5_submission.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Id', 'Predicted'])\n",
    "    test_id = 0\n",
    "    for i in prob_score_list:\n",
    "        writer.writerow([test_id, i])\n",
    "        test_id += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
