{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ca8e59-884d-4003-99c5-eba84bb28717",
   "metadata": {},
   "source": [
    "## We will be using one hot encoding method as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "798613ee-05aa-47cd-be47-4f21af3f4e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "# example of a multi-label classification task\n",
    "from sklearn.datasets import make_multilabel_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a193e-f9fd-4e72-8a20-9ea7e5a685e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 1: Preprocessing test and train data:\n",
    "1) add label to train data\n",
    "2) merge 'coauthor' and 'target' columns for test data\n",
    "3) one hot encode keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5576b20d-5fbd-49b3-bb68-704ba98103d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('../data/train.json', orient='index')\n",
    "test_df = pd.read_json('../data/test.json', orient='index')\n",
    "\n",
    "train_json = json.load(open('../data/train.json'))\n",
    "test_json = json.load(open('../data/train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "72a5bf28-a8a9-4fc6-b294-43b41334fa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue</th>\n",
       "      <th>keywords</th>\n",
       "      <th>year</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[470]</td>\n",
       "      <td>[260, 6, 390, 136, 7, 11, 17, 285, 288, 162, 4...</td>\n",
       "      <td>[2017]</td>\n",
       "      <td>[988]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[94]</td>\n",
       "      <td>[260, 454, 137, 14, 400, 274, 339, 213, 280, 2...</td>\n",
       "      <td>[2019]</td>\n",
       "      <td>[1001, 2123]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[31]</td>\n",
       "      <td>[390, 198, 7, 461, 462, 14, 404, 277, 24, 473,...</td>\n",
       "      <td>[2014]</td>\n",
       "      <td>[1578]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[6]</td>\n",
       "      <td>[195, 6, 390, 10, 459, 464, 338, 146, 276, 466...</td>\n",
       "      <td>[2010]</td>\n",
       "      <td>[1347, 2072]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[162]</td>\n",
       "      <td>[64, 1, 260, 457, 73, 147, 282, 27, 156, 43, 3...</td>\n",
       "      <td>[2016]</td>\n",
       "      <td>[1107, 995]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>[14]</td>\n",
       "      <td>[194, 260, 69, 73, 14, 462, 334, 17, 336, 280,...</td>\n",
       "      <td>[2015]</td>\n",
       "      <td>[1876]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>[5]</td>\n",
       "      <td>[64, 260, 261, 135, 7, 75, 332, 334, 15, 463, ...</td>\n",
       "      <td>[2016]</td>\n",
       "      <td>[1976]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>[58]</td>\n",
       "      <td>[451, 136, 459, 15, 146, 276, 342, 285, 222, 2...</td>\n",
       "      <td>[2004]</td>\n",
       "      <td>[646, 1131]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>[6]</td>\n",
       "      <td>[128, 64, 322, 260, 261, 388, 391, 455, 265, 1...</td>\n",
       "      <td>[2016]</td>\n",
       "      <td>[1684, 1040, 1713, 2124]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>[470]</td>\n",
       "      <td>[132, 271, 17, 19, 148, 278, 409, 287, 161, 29...</td>\n",
       "      <td>[2011]</td>\n",
       "      <td>[427]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      venue                                           keywords    year  \\\n",
       "0     [470]  [260, 6, 390, 136, 7, 11, 17, 285, 288, 162, 4...  [2017]   \n",
       "1      [94]  [260, 454, 137, 14, 400, 274, 339, 213, 280, 2...  [2019]   \n",
       "2      [31]  [390, 198, 7, 461, 462, 14, 404, 277, 24, 473,...  [2014]   \n",
       "3       [6]  [195, 6, 390, 10, 459, 464, 338, 146, 276, 466...  [2010]   \n",
       "4     [162]  [64, 1, 260, 457, 73, 147, 282, 27, 156, 43, 3...  [2016]   \n",
       "...     ...                                                ...     ...   \n",
       "1995   [14]  [194, 260, 69, 73, 14, 462, 334, 17, 336, 280,...  [2015]   \n",
       "1996    [5]  [64, 260, 261, 135, 7, 75, 332, 334, 15, 463, ...  [2016]   \n",
       "1997   [58]  [451, 136, 459, 15, 146, 276, 342, 285, 222, 2...  [2004]   \n",
       "1998    [6]  [128, 64, 322, 260, 261, 388, 391, 455, 265, 1...  [2016]   \n",
       "1999  [470]  [132, 271, 17, 19, 148, 278, 409, 287, 161, 29...  [2011]   \n",
       "\n",
       "                        author  \n",
       "0                        [988]  \n",
       "1                 [1001, 2123]  \n",
       "2                       [1578]  \n",
       "3                 [1347, 2072]  \n",
       "4                  [1107, 995]  \n",
       "...                        ...  \n",
       "1995                    [1876]  \n",
       "1996                    [1976]  \n",
       "1997               [646, 1131]  \n",
       "1998  [1684, 1040, 1713, 2124]  \n",
       "1999                     [427]  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba72d83-d262-48bd-814e-b2ecfb348eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df['venue'] = df.venue.replace('', 470).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b6424bdf-a2b6-4748-8ef4-44aa90cf59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add positive label\n",
    "train_df['label'] = 1\n",
    "train_df.head(3)\n",
    "\n",
    "train_df['venue'] = train_df.venue.replace('', 470).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "47fae15e-fdf7-4323-b5f7-c0dfcdb5f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 'coauthor' and 'target' columns for test data\n",
    "\n",
    "def add_column(coauthor, target):\n",
    "    return coauthor + [target]\n",
    "    \n",
    "test_df['author'] = test_df.apply(lambda x: add_column(x.coauthor, x.target), axis=1)\n",
    "test_df = test_df[['venue','keywords','year','author']]\n",
    "test_df.head(3)\n",
    "\n",
    "test_df['venue'] = test_df.venue.replace('', 470).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2af35276-7219-4d69-99bc-657795a88c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(column):\n",
    "    return [column]\n",
    "\n",
    "train_df['venue'] = train_df.apply(lambda x: to_list(x.venue), axis=1)\n",
    "test_df['venue'] = test_df.apply(lambda x: to_list(x.venue), axis=1)\n",
    "train_df['year'] = train_df.apply(lambda x: to_list(x.year), axis=1)\n",
    "test_df['year'] = test_df.apply(lambda x: to_list(x.year), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "83c9c6a2-6413-4243-88a9-dec693eb289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26108, 471)\n",
      "(26108, 500)\n",
      "(26108, 20)\n",
      "(26108, 2302)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode keywords and author column\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb_venue = MultiLabelBinarizer(sparse_output=True, classes=list(range(471)))\n",
    "venue_train = mlb_venue.fit_transform(train_df.venue).toarray()\n",
    "print(venue_train.shape)\n",
    "\n",
    "mlb_keywords = MultiLabelBinarizer(sparse_output=True, classes=list(range(500)))\n",
    "keywords_train = mlb_keywords.fit_transform(train_df.keywords).toarray()\n",
    "print(keywords_train.shape)\n",
    "\n",
    "mlb_year = MultiLabelBinarizer(sparse_output=True, classes=list(range(2000,2020)))\n",
    "year_train = mlb_year.fit_transform(train_df.year).toarray()\n",
    "print(year_train.shape)\n",
    "\n",
    "mlb_author = MultiLabelBinarizer(sparse_output=True, classes=list(range(2302)))\n",
    "author_train = mlb_author.fit_transform(train_df.author).toarray()\n",
    "print(author_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "323ef633-1752-4324-b7c0-b67808efa411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26108, 3293)\n",
      "(26108,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.hstack((venue_train, keywords_train, year_train, author_train)).astype('int')\n",
    "y_train = train_df.label\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3bdb9147-3c92-415d-8241-bc02ca0b13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import hamming\n",
    "import random\n",
    "\n",
    "random_index = random.sample(range(26108), 10000)\n",
    "neg_sample_index = []\n",
    "for i in random_index:\n",
    "    hd_row = []\n",
    "    for j in range(keywords_train.shape[0]):\n",
    "        hd = hamming(keywords_train[i], keywords_train[j])\n",
    "        hd_row.append(hd)\n",
    "    for k in range(3):\n",
    "        neg_index = hd_row.index(max(hd_row))\n",
    "        neg_sample_index.append([i, neg_index])\n",
    "        del hd_row[neg_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "ae7a7fb9-25ef-4b3c-ad5b-185b524a8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia_list = [item[0] for item in neg_sample_index]\n",
    "ib_list = [item[1] for item in neg_sample_index]\n",
    "\n",
    "neg_result_df = train_df.iloc[ia_list].copy().reset_index(drop=True)\n",
    "neg_result_df['author'] = train_df.iloc[ib_list].author.reset_index(drop=True)\n",
    "neg_result_df['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "c32e6940-57a5-4599-a775-a0b93fa6f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save hamming negative sample to csv\n",
    "neg_result_df.to_csv('negative_sample_hm.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7b4a596f-6c81-44e7-bddd-660227f38335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue</th>\n",
       "      <th>keywords</th>\n",
       "      <th>year</th>\n",
       "      <th>author</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[470]</td>\n",
       "      <td>[64, 1, 322, 134, 136, 396, 270, 144, 476, 481...</td>\n",
       "      <td>[2017]</td>\n",
       "      <td>[1605, 759]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0]</td>\n",
       "      <td>[258, 260, 389, 261, 390, 396, 400, 17, 146, 2...</td>\n",
       "      <td>[2013]</td>\n",
       "      <td>[2182]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[320, 454, 266, 462, 17, 339, 404, 342, 407, 2...</td>\n",
       "      <td>[2007]</td>\n",
       "      <td>[2176]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[260, 132, 333, 15, 400, 272, 146, 401, 278, 3...</td>\n",
       "      <td>[2013]</td>\n",
       "      <td>[1107]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[64, 385, 449, 450, 71, 73, 268, 80, 216, 25, ...</td>\n",
       "      <td>[2009]</td>\n",
       "      <td>[1414]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   venue                                           keywords    year  \\\n",
       "0  [470]  [64, 1, 322, 134, 136, 396, 270, 144, 476, 481...  [2017]   \n",
       "1    [0]  [258, 260, 389, 261, 390, 396, 400, 17, 146, 2...  [2013]   \n",
       "2    [1]  [320, 454, 266, 462, 17, 339, 404, 342, 407, 2...  [2007]   \n",
       "3    [2]  [260, 132, 333, 15, 400, 272, 146, 401, 278, 3...  [2013]   \n",
       "4    [3]  [64, 385, 449, 450, 71, 73, 268, 80, 216, 25, ...  [2009]   \n",
       "\n",
       "        author  label  \n",
       "0  [1605, 759]      1  \n",
       "1       [2182]      1  \n",
       "2       [2176]      1  \n",
       "3       [1107]      1  \n",
       "4       [1414]      1  "
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge negative sample and train set\n",
    "\n",
    "new_train_df = train_df.append(neg_result_df)\n",
    "new_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "abcd2c69-81cf-45fa-9362-f2112118f4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56108, 471)\n",
      "(56108, 500)\n",
      "(56108, 20)\n",
      "(56108, 2302)\n",
      "(56108, 3293)\n",
      "(56108,)\n"
     ]
    }
   ],
   "source": [
    "# one-hot new train_set\n",
    "\n",
    "new_venue_train = mlb_venue.transform(new_train_df.venue).toarray()\n",
    "new_keywords_train = mlb_keywords.transform(new_train_df.keywords).toarray()\n",
    "new_year_train = mlb_year.transform(new_train_df.year).toarray()\n",
    "new_author_train = mlb_author.transform(new_train_df.author).toarray()\n",
    "\n",
    "print(new_venue_train.shape)\n",
    "print(new_keywords_train.shape)\n",
    "print(new_year_train.shape)\n",
    "print(new_author_train.shape)\n",
    "\n",
    "new_X_train = np.hstack((new_venue_train, new_keywords_train, new_year_train, new_author_train)).astype('int')\n",
    "new_y_train = new_train_df.label\n",
    "\n",
    "print(new_X_train.shape)\n",
    "print(new_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "17497f1f-7212-4bb0-aeed-d6267adabce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(new_X_train, new_y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "375b5dfd-75e0-4ca8-b2e6-c8ed7bd16056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3293)\n"
     ]
    }
   ],
   "source": [
    "venue_test = mlb_venue.transform(test_df.venue).toarray()\n",
    "keywords_test = mlb_keywords.transform(test_df.keywords).toarray()\n",
    "year_test = mlb_year.transform(test_df.year).toarray()\n",
    "author_test = mlb_author.transform(test_df.author).toarray()\n",
    "\n",
    "X_test = np.hstack((venue_test, keywords_test, year_test, author_test)).astype('int')\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "96fcbe80-ee62-4de2-8ccb-a894b0d217c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986059566286253"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter = 10000)\n",
    "clf.fit(X_train_a, y_train_a)\n",
    "\n",
    "roc_auc_score(y_test_a, clf.predict_proba(X_test_a)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "9d5d5cee-b3af-441c-9010-397b2d38c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prob = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "7d5cb7bc-b3c6-40f9-b736-b233f27969de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "c = 0\n",
    "for i in X_test:\n",
    "    prob.append(result[c][i-1])\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "57942f68-3899-4b7c-853b-e810582d014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.994896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.997874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  predicted\n",
       "0   0   0.997977\n",
       "1   1   0.994896\n",
       "2   2   0.999017\n",
       "3   3   0.998593\n",
       "4   4   0.997874"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = [item[1] for item in result_prob]\n",
    "ids = list(range(2000))\n",
    "submission_df = pd.DataFrame({'Id':ids, 'predicted':predicted})\n",
    "\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc8161-e8f9-4067-82fe-4e3ee9aac3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_tom.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e7432-7697-401b-b479-c65ec74e96e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
